{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Webscraping Yahoo Finance\n",
    "### Introduction\n",
    "In this notebook, we shall learn how to scrape websites for information using Python. \n",
    "\n",
    "\n",
    "The following are general steps to scrape websites:\n",
    "1. Identify target website.\n",
    "2. Learn how the website constructs their URL so we can retrieve the desired page from the website.\n",
    "3. Programmatically retrieve websites with the URL we reverse-engineered from the website.\n",
    "4. Use libraries to traverse and obtain information we need from website.\n",
    "5. Organise the information and return in desired format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some of the libraries we need to construct\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from time import sleep\n",
    "import json\n",
    "import argparse\n",
    "from collections import OrderedDict\n",
    "from time import sleep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1. Identify target website\n",
    "\n",
    "Our target website is Yahoo Finance. Our desired information is the stock information available on the website. \n",
    "\n",
    "Before we start scraping, have a look at how a typical stock information page looks like: \n",
    "\n",
    "__[Apple - AAPL](https://finance.yahoo.com/quote/AAPL?p=AAPL)__ : https://finance.yahoo.com/quote/AAPL?p=AAPL\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2. Deconstruct URL\n",
    "\n",
    "We don't want to manually type in the search box and search for stocks we want. Instead, by studying the URL, we can deconstruct them, and by tweaking them, we can get to the page that holds the stock information we want. \n",
    "\n",
    "\n",
    "For example, look at the URL in **Step 1**. The ticker symbol of the Apple is **AAPL**. Notice that **AAPL** repeats twice in the URL. \n",
    "\n",
    "Perhaps, if we replace **AAPL** in the URL with any ticker symbol we want, we can get the stock information for that stock. \n",
    "\n",
    "For example, try __[Google - GOOG](https://finance.yahoo.com/quote/GOOG?p=GOOG)__ : https://finance.yahoo.com/quote/GOOG?p=GOOG\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_url(ticker):\n",
    "    base_url = \"http://finance.yahoo.com/quote/{0}?p={0}\"\n",
    "    url = base_url.replace(\"{0}\", ticker)\n",
    "    return url\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "## Step 3. Retrieve website\n",
    "\n",
    "Now that we know which URL to go to, we can retrieve the webpage programmatically. \n",
    "\n",
    "To do so, we use a Python Library called **requests**, which we have imported above.\n",
    "\n",
    "After retrieving the webpage, we then pass it to another library, **BeautifulSoup**, a library that will greatly faciliate our webscraping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_website(url):\n",
    "    response = requests.get(url)\n",
    "    html = response.text\n",
    "    parsed_html = BeautifulSoup(html, 'html.parser')\n",
    "    return parsed_html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4. Retrieve desired information\n",
    "\n",
    "This step is probably the hardest step. \n",
    "\n",
    "We need to look at our a website is constructed, and utilise bits of the metadata to reliably retrieve the information we need.\n",
    "\n",
    "\n",
    "### Chrome Developer Tool\n",
    "To do so, we can open the **Chrome Developer Tools**. \n",
    "\n",
    "On the Yahoo Finance page, \n",
    "1. hover the mouse over any element you would like to find out more information about,\n",
    "2. Right-click on it.\n",
    "3. Then select inspect.\n",
    "\n",
    "A side bar should popup with the raw HTML information. As you hover your mouse over the HTML elements, it should highlight the location of the element on the page. \n",
    "\n",
    "\n",
    "\n",
    "### Example\n",
    "In the code below, we use the `find` method to look for a HTML element with *tag* `span` and *class* `Fz(36px)`. \n",
    "\n",
    "We then retrieve the textual information nested inside this element with `getText()`.\n",
    "\n",
    "\n",
    "\n",
    "### Your turn!\n",
    "Now, try to identify and scrape more financial data.\n",
    "\n",
    "Here's a list for you to try:\n",
    "1. Beta\n",
    "2. PE Ratio (TTM)\n",
    "3. EPS (TTM)\n",
    "4. Earnings Date\n",
    "5. Dividend & Yield"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_information(ticker, url, website):\n",
    "    \n",
    "    ticker_price = website.find(\"span\", class_=\"Fz(36px)\").getText()\n",
    "######## Add in your webscrapping code here to scrape more information #############\n",
    "    \n",
    "    \n",
    "    \n",
    "####################################################################################\n",
    "######## Remember to add the information to the summary_data object below ##########\n",
    "    summary_data = {\n",
    "        'ticker': ticker,\n",
    "        'ticker_price': ticker_price,\n",
    "        'url': url     \n",
    "    }\n",
    "    return summary_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Putting it all together\n",
    "\n",
    "The method below puts everything together. Try running it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting from URL: http://finance.yahoo.com/quote/AAPL?p=AAPL\n",
      "{'ticker': 'AAPL', 'ticker_price': '156.875', 'url': 'http://finance.yahoo.com/quote/AAPL?p=AAPL'}\n"
     ]
    }
   ],
   "source": [
    "def get_ticker_data(ticker):\n",
    "    \n",
    "    url = construct_url(ticker)\n",
    "    print(\"getting from URL: \" + url) #jupyter_\n",
    "    website = retrieve_website(url)\n",
    "\n",
    "    summary_data = get_information(ticker, url, website)\n",
    "    \n",
    "    return summary_data\n",
    "\n",
    "\n",
    "print(get_ticker_data(\"AAPL\")) #jupyter_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
